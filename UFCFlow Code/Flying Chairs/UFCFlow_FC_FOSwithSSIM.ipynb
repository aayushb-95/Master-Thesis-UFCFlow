{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"UFCFlow_FC_FOSwithSSIM.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"cells":[{"cell_type":"code","metadata":{"id":"YN9_HRBvPAf_"},"source":["import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YC1LcrDjPMi7"},"source":["# Initializing all the required libraries\n","import re\n","import os\n","import sys\n","import cv2\n","import math\n","import time\n","import imageio\n","import numpy as np\n","import pandas as pd\n","from PIL import Image\n","from scipy import misc\n","from tensorflow import keras\n","import matplotlib.colors as cl\n","import matplotlib.pyplot as plt\n","import tensorflow_addons as tfa\n","from urllib.request import urlopen\n","from matplotlib.image import imread\n","import tensorflow.keras.backend as bk\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import LeakyReLU\n","from tensorflow_addons.optimizers import AdamW\n","from tensorflow_addons.layers import CorrelationCost\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.layers import Conv2D, Conv2DTranspose, InputLayer, Concatenate"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MvynmvcZ1Ok5"},"source":["# code to read/write the flow file \n","\n","def read(file):\n","    if file.endswith('.float3'): return readFloat(file)\n","    elif file.endswith('.flo'): return readFlow(file)\n","    elif file.endswith('.ppm'): return readImage(file)\n","    elif file.endswith('.pgm'): return readImage(file)\n","    elif file.endswith('.png'): return readImage(file)\n","    elif file.endswith('.jpg'): return readImage(file)\n","    elif file.endswith('.pfm'): return readPFM(file)[0]\n","    else: raise Exception('don\\'t know how to read %s' % file)\n","\n","def write(file, data):\n","    if file.endswith('.float3'): return writeFloat(file, data)\n","    elif file.endswith('.flo'): return writeFlow(file, data)\n","    elif file.endswith('.ppm'): return writeImage(file, data)\n","    elif file.endswith('.pgm'): return writeImage(file, data)\n","    elif file.endswith('.png'): return writeImage(file, data)\n","    elif file.endswith('.jpg'): return writeImage(file, data)\n","    elif file.endswith('.pfm'): return writePFM(file, data)\n","    else: raise Exception('don\\'t know how to write %s' % file)\n","\n","def readPFM(file):\n","    file = open(file, 'rb')\n","\n","    color = None\n","    width = None\n","    height = None\n","    scale = None\n","    endian = None\n","\n","    header = file.readline().rstrip()\n","    if header.decode(\"ascii\") == 'PF':\n","        color = True\n","    elif header.decode(\"ascii\") == 'Pf':\n","        color = False\n","    else:\n","        raise Exception('Not a PFM file.')\n","\n","    dim_match = re.match(r'^(\\d+)\\s(\\d+)\\s$', file.readline().decode(\"ascii\"))\n","    if dim_match:\n","        width, height = list(map(int, dim_match.groups()))\n","    else:\n","        raise Exception('Malformed PFM header.')\n","\n","    scale = float(file.readline().decode(\"ascii\").rstrip())\n","    if scale < 0: # little-endian\n","        endian = '<'\n","        scale = -scale\n","    else:\n","        endian = '>' # big-endian\n","\n","    data = np.fromfile(file, endian + 'f')\n","    shape = (height, width, 3) if color else (height, width)\n","\n","    data = np.reshape(data, shape)\n","    data = np.flipud(data)\n","    return data, scale\n","\n","def readImage(name):\n","    if name.endswith('.pfm') or name.endswith('.PFM'):\n","        data = readPFM(name)[0]\n","        if len(data.shape)==3:\n","            return data[:,:,0:3]\n","        else:\n","            return data\n","\n","    return imageio.imread(name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"anEWtg7uPSyq"},"source":["# Reading a csv file where each entry consist of img1, img2, flow column \n","df= pd.read_csv('')\n","\n","# Reading images from directory\n","images_dir = \"\"\n","\n","# Function to load the image\n","def load_image(img_1,img_2):\n","    \n","    img1 = readImage(images_dir+img_1.decode(\"utf-8\"))\n","    img2 = readImage(images_dir+img_2.decode(\"utf-8\"))\n","    return img1, img2\n","   "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zmKxDNfOydfC"},"source":["print(\"Total number of image pairs\",len(df))\n","test_set = df.sample(frac = 0.0279, random_state=42)         #Creating test set. Random sampling with a random seed value\n","print(\"Total number of test image pairs\",len(test_set))\n","test_img_1_list = test_set['img1'].tolist()                   #Coverting column to list and pass for testing\n","test_img_2_list = test_set['img2'].tolist()\n","test_flow_list = test_set['flow'].tolist()\n","for i in range(len(test_flow_list)):\n","  df =df[df['flow'] != test_flow_list[i]]                   # Removing all the test rows from the train set\n","print(\"Total number of training image pairs\",len(df))\n","\n","img_1_list = df['img1'].tolist()                            #coverting column to list to pass it for mapping function for tf.Dataset\n","img_2_list = df['img2'].tolist()\n","flow_list = df['flow'].tolist()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ptYwwPWdydfD"},"source":["# Train-Test CSV generation\n","df.to_csv('')\n","test_set.to_csv('')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B6c_UjjLPZ_T"},"source":["#function to map images and flow \n","def map_func1(img_1,img_2):\n","    img1, img2 = load_image(img_1,img_2)\n","    # mapping function for images to dataset\n","    return tf.dtypes.cast(img1, tf.float32), tf.dtypes.cast(img2, tf.float32)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LAOVamqLPcXR"},"source":["#code to load the images the and flow into the dataset \n","batch_size = 16\n","dataset1 = tf.data.Dataset.from_tensor_slices((img_1_list,img_2_list))\n","\n","\n","# Use map to load the numpy files in parallel\n","dataset1 = dataset1.map(lambda item1, item2: tf.numpy_function(\n","          map_func1, [item1, item2], [tf.float32, tf.float32]),num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","\n","# Shuffle and batch\n","#dataset1 = dataset1.cache()\n","dataset1 = dataset1.shuffle(buffer_size=64)\n","dataset1 = dataset1.batch(batch_size)\n","dataset1 = dataset1.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gFAKBfajydfE"},"source":["num_elements = tf.data.experimental.cardinality(dataset1).numpy()\n","print(\"Total number of batches:\",num_elements)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b68U1POoPQQK"},"source":["def crop_like(input, target): #shape adjustment\n","    if input.shape[1:3] == target.shape[1:3]:\n","        return input\n","    else:\n","        return input[:, :target.shape[1],:target.shape[2],:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ezPIfyX4k4WO"},"source":["class UFCFlow(tf.keras.Model):        #UFCFlow Model\n","\n","  def __init__(self):\n","    super(UFCFlow, self).__init__()\n","    self.i1= InputLayer(input_shape=(384,512,3))                                            # Input Layer for first image frame\n","    self.i2= InputLayer(input_shape=(384,512,3))                                            # Input Layer for second image frame\n","      #input 1 path\n","    self.conva_00= Conv2D(16,7,strides=1,padding='same')\n","    self.conva_00_act = LeakyReLU(alpha=0.1) \n","    self.conva_01= Conv2D(32,7,strides=1,padding='same')\n","    self.conva_01_act = LeakyReLU(alpha=0.1) \n","    self.conva_1= Conv2D(64,7,strides=2,padding='same')\n","    self.conva_1_act = LeakyReLU(alpha=0.1)       \n","    self.conva_2= Conv2D(128,5,strides=2,padding='same')\n","    self.conva_2_act = LeakyReLU(alpha=0.1)\n","    self.conva_3= Conv2D(256,5,strides=2,padding='same')\n","    self.conva_3_act = LeakyReLU(alpha=0.1)\n","\n","      #input 2 path\n","    self.convb_00= Conv2D(16,7,strides=1,padding='same')\n","    self.convb_00_act = LeakyReLU(alpha=0.1) \n","    self.convb_01= Conv2D(32,7,strides=1,padding='same')\n","    self.convb_01_act = LeakyReLU(alpha=0.1)\n","    self.convb_1= Conv2D(64,7,strides=2,padding='same')\n","    self.convb_1_act =LeakyReLU(alpha=0.1)\n","    self.convb_2= Conv2D(128,5,strides=2,padding='same')\n","    self.convb_2_act =LeakyReLU(alpha=0.1)\n","    self.convb_3= Conv2D(256,5,strides=2,padding='same')\n","    self.convb_3_act =LeakyReLU(alpha=0.1)\n","\n","    # Correalation layer\n","    self.cc = CorrelationCost(1,20,1,2,20,data_format='channels_last')\n","    self.cr_1_act= LeakyReLU(alpha=0.1)\n","    self.conva_redir= Conv2D(32,1,strides=1)\n","    self.conva_redir_act =LeakyReLU(alpha=0.1)\n","    self.vol_1= Concatenate(axis=3)\n","    \n","    #Single stream\n","    self.conv3_1= Conv2D(256,3,strides=1,padding='same')\n","    self.conv3_1_act= LeakyReLU(alpha=0.1)\n","    self.conv4= Conv2D(512,3,strides=2,padding='same')\n","    self.conv4_act= LeakyReLU(alpha=0.1)\n","    self.conv4_1= Conv2D(512,3,strides=1,padding='same')\n","    self.conv4_1_act= LeakyReLU(alpha=0.1)\n","    self.conv5= Conv2D(512,3,strides=2,padding='same')\n","    self.conv5_act= LeakyReLU(alpha=0.1)\n","    self.conv5_1= Conv2D(512,3,strides=1,padding='same')\n","    self.conv5_1_act= LeakyReLU(alpha=0.1)\n","    self.conv6= Conv2D(1024,3,strides=2,padding='same')\n","    self.conv6_act= LeakyReLU(alpha=0.1)\n","    self.conv6_1= Conv2D(1024,3,strides=1,padding='same')\n","    self.conv6_1_act= LeakyReLU(alpha=0.1)\n","\n","    #Refinement network\n","    self.pf6= Conv2D(2,3,strides=1,padding='same')\n","    self.dc5= Conv2DTranspose(512,4,strides=2,padding='same')\n","    self.dc5_act= LeakyReLU(alpha=0.1)\n","    self.up_6to5= Conv2DTranspose(2,4,strides=2,padding='same')\n","    self.con_5= Concatenate(axis=3)\n","\n","    self.pf5= Conv2D(2,3,strides=1,padding='same')\n","    self.dc4= Conv2DTranspose(256,4,strides=2,padding='same')\n","    self.dc4_act= LeakyReLU(alpha=0.1)\n","    self.up_5to4= Conv2DTranspose(2,4,strides=2,padding='same')\n","    self.con_4= Concatenate(axis=3)\n","\n","    self.pf4= Conv2D(2,3,strides=1,padding='same')\n","    self.dc3= Conv2DTranspose(128,4,strides=2,padding='same')\n","    self.dc3_act= LeakyReLU(alpha=0.1)\n","    self.up_4to3= Conv2DTranspose(2,4,strides=2,padding='same')\n","    self.con_3= Concatenate(axis=3)\n","\n","    self.pf3= Conv2D(2,3,strides=1,padding='same')\n","    self.dc2= Conv2DTranspose(64,4,strides=2,padding='same')\n","    self.dc2_act= LeakyReLU(alpha=0.1)\n","    self.up_3to2= Conv2DTranspose(2,4,strides=2,padding='same')\n","    self.con_2=Concatenate(axis=3)\n","\n","    self.pf2= Conv2D(2,3,strides=1,padding='same')\n","    self.dc1= Conv2DTranspose(32,4,strides=2,padding='same')\n","    self.dc1_act= LeakyReLU(alpha=0.1)\n","    self.up_2to1= Conv2DTranspose(2,4,strides=2,padding='same')\n","    self.con_1=Concatenate(axis=3)\n","    self.pf1= Conv2D(2,3,strides=1,padding='same')\n","\n","  def call(self, input1,input2,training=False):\n","\n","    i_1=self.i1(input1)\n","    cona00=self.conva_00(i_1)\n","    cona00_act=self.conva_00_act(cona00)\n","    cona01=self.conva_01(cona00_act)\n","    cona01_act=self.conva_01_act(cona01)\n","    cona1=self.conva_1(cona01_act)\n","    cona1_act=self.conva_1_act(cona1)\n","    cona2=self.conva_2(cona1_act)\n","    cona2_act=self.conva_2_act(cona2)\n","    cona3=self.conva_3(cona2_act)\n","    cona3_act=self.conva_3_act(cona3)\n","\n","    i_2=self.i2(input2)\n","    conb00=self.convb_00(i_2)\n","    conb00_act=self.convb_00_act(conb00)\n","    conb01=self.convb_01(conb00_act)\n","    conb01_act=self.convb_01_act(conb01)\n","    conb1=self.convb_1(conb01_act)\n","    conb1_act=self.convb_1_act(conb1)\n","    conb2=self.convb_2(conb1_act)\n","    conb2_act=self.convb_2_act(conb2)\n","    conb3=self.convb_3(conb2_act)\n","    conb3_act=self.convb_3_act(conb3)\n","\n","    cc1=self.cc([cona3_act,conb3_act])\n","    cc1_act=self.cr_1_act(cc1)\n","    cona_r=self.conva_redir(cona3_act)\n","    cona_r_act=self.conva_redir_act(cona_r)\n","    v1=self.vol_1([cc1_act,cona_r_act]) \n","\n","    con3_1=self.conv3_1(v1)\n","    con3_1_act=self.conv3_1_act(con3_1)\n","    con4=self.conv4(con3_1_act)\n","    con4_act=self.conv4_act(con4)\n","    con4_1=self.conv4_1(con4_act)\n","    con4_1_act=self.conv4_1_act(con4_1)\n","    con5=self.conv5(con4_1_act)\n","    con5_act=self.conv5_act(con5)\n","    con5_1=self.conv5_1(con5_act)\n","    con5_1_act=self.conv5_1_act(con5_1)\n","    con6=self.conv6(con5_1_act)\n","    con6_act=self.conv6_act(con6)\n","    con6_1=self.conv6_1(con6_act)\n","    con6_1_act=self.conv6_1_act(con6_1)\n","\n","    pf_6=self.pf6(con6_1_act)\n","    dc_5=self.dc5(con6_1_act)\n","    dc_5_act=self.dc5_act(dc_5)\n","    ups_6to5=self.up_6to5(pf_6)\n","    concat5=self.con_5([con5_1_act,dc_5_act,ups_6to5])\n","\n","    pf_5=self.pf5(concat5)\n","    dc_4=self.dc4(concat5)\n","    dc_4_act=self.dc4_act(dc_4)\n","    ups_5to4=self.up_5to4(pf_5)\n","    concat4=self.con_4([con4_1_act,dc_4_act,ups_5to4])\n","\n","    pf_4=self.pf4(concat4)\n","    dc_3=self.dc3(concat4)\n","    dc_3_act=self.dc3_act(dc_3)\n","    dc_3_crop=crop_like(dc_3_act,con3_1_act)\n","    ups_4to3=self.up_4to3(pf_4)\n","    ups_4to3_crop=crop_like(ups_4to3,con3_1_act)\n","    concat3=self.con_3([con3_1_act,dc_3_crop,ups_4to3_crop])\n","\n","    pf_3=self.pf3(concat3)\n","    dc_2=self.dc2(concat3)\n","    dc_2_act=self.dc2_act(dc_2)\n","    dc_2_crop=crop_like(dc_2_act,cona2_act)\n","    ups_3to2=self.up_3to2(pf_3)\n","    ups_3to2_crop=crop_like(ups_3to2,cona2_act)\n","    concat2=self.con_2([cona2_act,dc_2_crop,ups_3to2_crop])\n","\n","    pf_2=self.pf2(concat2)\n","    dc_1=self.dc1(concat2)\n","    dc_1_act=self.dc1_act(dc_1)\n","    ups_2to1=self.up_2to1(pf_2)\n","    concat1=self.con_1([cona1_act,dc_1_act,ups_2to1])\n","    pf_1=self.pf1(concat1)\n","    flow=tf.image.resize(pf_1,tf.stack([384,512]),method='bilinear')\n","\n","    return  {'flow': flow ,'predict_flow6': pf_6, 'predict_flow5': pf_5, 'predict_flow4': pf_4, 'predict_flow3': pf_3, 'predict_flow2': pf_2,'predict_flow1': pf_1}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"58CLMt3QPmdB"},"source":["model = UFCFlow()     # Model initialization"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bd57ixKXPhBh"},"source":["# Charbonnier Penalty Function\n","def charbonnier_loss(delta, alpha=0.50, epsilon=1e-3):\n","    loss = tf.reduce_mean(tf.pow(tf.square(delta)+tf.square(epsilon), alpha))\n","    return loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B0nM1_vNVpIc"},"source":["# Photometric Loss Function\n","def PG_loss(y,x):\n","  alpha=0.50\n","  epsilon=1e-3\n","  Pl_loss = tf.reduce_mean(tf.pow(tf.square(tf.subtract(y,x))+tf.square(epsilon), alpha))\n","  loss_PG = (Pl_loss)/len(df)\n","  return loss_PG\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Np6R5liP34FY"},"source":["# First-Order Smoothness Loss Function\n","def conv2d(x, weights):\n","    return tf.nn.conv2d(x, weights, strides=[1, 1, 1, 1], padding='SAME')\n","\n","def smoothness_deltas(flow):\n","    filter_x = [[0, 0, 0], [0, 1, -1], [0, 0, 0]]\n","    filter_y = [[0, 0, 0], [0, 1, 0], [0, -1, 0]]\n","    weight_array = np.ones([3, 3, 1, 2])\n","    weight_array[:, :, 0, 0] = filter_x\n","    weight_array[:, :, 0, 1] = filter_y\n","    weights = tf.constant(weight_array, dtype=tf.float32)\n","\n","    flow_u, flow_v = tf.split(axis=3, num_or_size_splits=2, value=flow)\n","    delta_u = conv2d(flow_u, weights)\n","    delta_v = conv2d(flow_v, weights)\n","    return delta_u, delta_v\n","\n","def smoothness_loss(flow):\n","    delta_u, delta_v = smoothness_deltas(flow)\n","    loss_u = charbonnier_loss(delta_u)\n","    loss_v = charbonnier_loss(delta_v)\n","    return (loss_u + loss_v)/len(df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z3QUqiKSydfJ"},"source":["# Structural Similarity Index Loss Function\n","def SSIM(y,x): \n","    C1 = 0.01**2\n","    C2 = 0.03**2\n","    x = tf.keras.layers.ZeroPadding2D()(x)\n","    y = tf.keras.layers.ZeroPadding2D()(y)\n","    mu_x_pool = tf.keras.layers.AveragePooling2D(pool_size=(3, 3), strides=1)(x)\n","    mu_y_pool = tf.keras.layers.AveragePooling2D(pool_size=(3, 3), strides=1)(y)\n","    \n","    sigma_x = tf.keras.layers.AveragePooling2D(pool_size=(3, 3), strides=1)(x**2) - mu_x_pool**2\n","    sigma_y = tf.keras.layers.AveragePooling2D(pool_size=(3, 3), strides=1)(y**2) - mu_y_pool**2\n","    sigma_xy = tf.keras.layers.AveragePooling2D(pool_size=(3, 3), strides=1)(x*y) - mu_x_pool* mu_y_pool\n","    \n","    SSIM_n = (2*mu_x_pool*mu_y_pool + C1)*(2*sigma_xy + C2)\n","    SSIM_d = (mu_x_pool**2 + mu_y_pool**2 + C1)*(sigma_x + sigma_y + C2)\n","    SSIM_loss =  tf.clip_by_value((1- SSIM_n/SSIM_d)/2,0,1)   \n","    return SSIM_loss/len(df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"denCicplrMh4"},"source":["def image_warp(im, flow):\n","    \"\"\"Performs a backward warp of an image using the predicted flow.\n","    Args:\n","        im: Batch of images. [num_batch, height, width, channels]\n","        flow: Batch of flow vectors. [num_batch, height, width, 2]\n","    Returns:\n","        warped: transformed image of the same shape as the input image.\n","    \"\"\"\n","   \n","\n","    num_batch, height, width, channels = tf.unstack(tf.shape(im))\n","    max_x = tf.cast(width - 1, 'int32')\n","    max_y = tf.cast(height - 1, 'int32')\n","    zero = tf.zeros([], dtype='int32')\n","\n","        # We have to flatten our tensors to vectorize the interpolation\n","    im_flat = tf.reshape(im, [-1, channels])\n","    flow_flat = tf.reshape(flow, [-1, 2])\n","\n","        # Floor the flow, as the final indices are integers\n","        # The fractional part is used to control the bilinear interpolation.\n","    flow_floor = tf.cast(tf.floor(flow_flat),dtype=tf.int32)\n","    bilinear_weights = flow_flat - tf.floor(flow_flat)\n","\n","        # Construct base indices which are displaced with the flow\n","    pos_x = tf.tile(tf.range(width), [height * num_batch])\n","    grid_y = tf.tile(tf.expand_dims(tf.range(height), 1), [1, width])\n","    pos_y = tf.tile(tf.reshape(grid_y, [-1]), [num_batch])\n","\n","    x = flow_floor[:, 0]\n","    y = flow_floor[:, 1]\n","    xw = bilinear_weights[:, 0]\n","    yw = bilinear_weights[:, 1]\n","\n","        # Compute interpolation weights for 4 adjacent pixels\n","        # expand to num_batch * height * width x 1 for broadcasting in add_n below\n","    wa = tf.expand_dims((1 - xw) * (1 - yw), 1) # top left pixel\n","    wb = tf.expand_dims((1 - xw) * yw, 1) # bottom left pixel\n","    wc = tf.expand_dims(xw * (1 - yw), 1) # top right pixel\n","    wd = tf.expand_dims(xw * yw, 1) # bottom right pixel\n","\n","    x0 = pos_x + x\n","    x1 = x0 + 1\n","    y0 = pos_y + y\n","    y1 = y0 + 1\n","\n","    x0 = tf.clip_by_value(x0, zero, max_x)\n","    x1 = tf.clip_by_value(x1, zero, max_x)\n","    y0 = tf.clip_by_value(y0, zero, max_y)\n","    y1 = tf.clip_by_value(y1, zero, max_y)\n","\n","    dim1 = width * height\n","    batch_offsets = tf.range(num_batch) * dim1\n","    base_grid = tf.tile(tf.expand_dims(batch_offsets, 1), [1, dim1])\n","    base = tf.reshape(base_grid, [-1])\n","\n","    base_y0 = base + y0 * width\n","    base_y1 = base + y1 * width\n","    idx_a = base_y0 + x0\n","    idx_b = base_y1 + x0\n","    idx_c = base_y0 + x1\n","    idx_d = base_y1 + x1\n","\n","    Ia = tf.gather(im_flat, idx_a)\n","    Ib = tf.gather(im_flat, idx_b)\n","    Ic = tf.gather(im_flat, idx_c)\n","    Id = tf.gather(im_flat, idx_d)\n","\n","    warped_flat = tf.add_n([wa * Ia, wb * Ib, wc * Ic, wd * Id])\n","    warped = tf.reshape(warped_flat, [num_batch, height, width, channels])\n","\n","    return warped"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3RzF13aSPnwR"},"source":["# Multi-Scale Loss Function for Photometric Loss\n","def loss_function(img1, img2, pred):\n","  pred6 = pred['predict_flow6']\n","  size = [pred6.shape[1], pred6.shape[2]]\n","  df6 = tf.image.resize(img2, tf.stack(size))\n","  df6_warp = image_warp(df6,pred6)\n","  df6_img1 = tf.image.resize(img1, tf.stack(size))\n","  pl6 = 0.32 * (PG_loss(df6_img1,df6_warp))\n","\n","  pred5=pred['predict_flow5']\n","  size = [pred5.shape[1], pred5.shape[2]]\n","  df5 = tf.image.resize(img2, tf.stack(size))\n","  df5_warp = image_warp(df5,pred5)\n","  df5_img1 = tf.image.resize(img1, tf.stack(size))\n","  pl5 = 0.32 * (PG_loss(df5_img1,df5_warp))\n","\n","  pred4=pred['predict_flow4']\n","  size = [pred4.shape[1], pred4.shape[2]]\n","  df4 = tf.image.resize(img2, tf.stack(size))\n","  df4_warp = image_warp(df4,pred4)\n","  df4_img1 = tf.image.resize(img1, tf.stack(size))\n","  pl4 = 0.32 * (PG_loss(df4_img1,df4_warp))\n","\n","  pred3=pred['predict_flow3']\n","  size = [pred3.shape[1], pred3.shape[2]]\n","  df3 = tf.image.resize(img2, tf.stack(size))\n","  df3_warp = image_warp(df3,pred3)\n","  df3_img1 = tf.image.resize(img1, tf.stack(size))\n","  pl3 = 0.32 * (PG_loss(df3_img1,df3_warp))\n","\n","  pred2=pred['predict_flow2']\n","  size = [pred2.shape[1], pred2.shape[2]]\n","  df2 = tf.image.resize(img2, tf.stack(size))\n","  df2_warp = image_warp(df2,pred2)\n","  df2_img1 = tf.image.resize(img1, tf.stack(size))\n","  pl2 = 0.32 * (PG_loss(df2_img1,df2_warp))\n","\n","  pred1=pred['predict_flow1']\n","  size = [pred1.shape[1], pred1.shape[2]]\n","  df1 = tf.image.resize(img2, tf.stack(size))\n","  df1_warp = image_warp(df1,pred1)\n","  df1_img1 = tf.image.resize(img1, tf.stack(size))\n","  pl1 = 0.64 * (PG_loss(df1_img1,df1_warp))\n","\n","  loss = tf.math.add_n([pl6,pl5,pl4,pl3,pl2,pl1])\n","\n","  return loss\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uqFPrvy_4FVU"},"source":["# Multi-Scale Loss Function for Smoothness Loss\n","def loss_function1(pred):\n","    pred6=pred['predict_flow6']\n","    smooth_loss6 = 0.32*(smoothness_loss(pred6))\n","    pred5=pred['predict_flow5']\n","    smooth_loss5 = 0.32*(smoothness_loss(pred5))\n","    pred4=pred['predict_flow4']\n","    smooth_loss4 = 0.32*(smoothness_loss(pred4))\n","    pred3=pred['predict_flow3']\n","    smooth_loss3 = 0.32*(smoothness_loss(pred3))\n","    pred2=pred['predict_flow2']\n","    smooth_loss2 = 0.32*(smoothness_loss(pred2))\n","    pred1=pred['predict_flow1']\n","    smooth_loss1 = 0.64*(smoothness_loss(pred1))\n","    loss = tf.math.add_n([smooth_loss6,smooth_loss5,smooth_loss4,smooth_loss3,smooth_loss2,smooth_loss1])\n","    return loss\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lKVqMWxEydfK"},"source":["# SSIM Loss computation\n","def loss_function2(img1, img2, pred):\n","  pred1=pred['predict_flow1']\n","  size = [pred1.shape[1], pred1.shape[2]]\n","  df1 = tf.image.resize(img2, tf.stack(size))\n","  df1_warp = image_warp(df1,pred1)\n","  df1_img1 = tf.image.resize(img1, tf.stack(size))\n","  pl1 = SSIM(df1_img1,df1_warp)\n","\n","  loss = tf.math.add_n([pl1])\n","\n","  return loss\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tf1YphA8PlEB"},"source":["# Custom Adam Optimizer with Weight Decay\n","optimizer= AdamW(weight_decay=0.0004, learning_rate=0.0001, beta_1=0.9, beta_2=0.999)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RXEfej7929jm"},"source":["# Model Checkpoint Creation and Loading\n","checkpoint_path = \"\"\n","ckpt = tf.train.Checkpoint(model=model,optimizer = optimizer)\n","ckpt.restore(tf.train.latest_checkpoint(checkpoint_path))\n","ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i_7z9KTF3KJE"},"source":["start_epoch = 0\n","if ckpt_manager.latest_checkpoint:\n","    start_epoch = int(ckpt_manager.latest_checkpoint.split('-')[-1])\n","print(start_epoch)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E3akFK0wPpI5"},"source":["# Code for computing gradients \n","def train_step(input1,input2):\n","    loss = 0\n","    l1=1\n","    l2=2\n","\n","    with tf.GradientTape() as tape:\n","        predict = model(input1,input2)\n","        loss = loss_function(input1,input2,predict)\n","        loss1 = loss_function1(predict)\n","        loss2 = loss_function2(input1,input2,predict)\n","        final_loss = loss + l1*loss1 + l2*loss2\n","\n","    trainable_variables = model.trainable_variables\n","    gradients = tape.gradient(final_loss, trainable_variables)\n","    optimizer.apply_gradients(zip(gradients, trainable_variables))\n","\n","    return loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_WJg0v6cPrQJ","scrolled":false},"source":["#Code for inputting the number of epochs to train and print the loss values \n","EPOCHS = 0\n","loss_list =[]\n","for epoch in range(start_epoch, EPOCHS):\n","    start = time.time()\n","    total_loss = 0\n","\n","    for (batch, (img1,img2)) in enumerate(dataset1):\n","        batch_loss= train_step(img1,img2)\n","        total_loss += batch_loss\n","        \n","        \n","        if batch % 100 == 0:\n","            print ('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, batch_loss.numpy()))\n","    loss_list.append(total_loss)\n","\n","    if epoch % 1 == 0:\n","      print(\"Saving model\\n\")\n","      ckpt_manager.save()\n","    print ('Epoch {} Loss {:.6f}'.format(epoch + 1,total_loss))\n","    print ('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1RYg-LCsPs4x"},"source":["# Plotting Loss graph and saving loss values in a text file\n","plt.plot(loss_list)\n","plt.imshow\n","plt.savefig(\"plot.png\",dpi=400)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q1deRiTCb43K"},"source":["numpy_loss_history = numpy.array(loss_list)\n","numpy.savetxt(\"train.txt\", numpy_loss_history, delimiter=\",\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ue6q3LJfb43U"},"source":["UNKNOWN_FLOW_THRESH = 1e7\n","def visualize_flow_train(flow,i, mode='Y'):\n","    if mode == 'Y':\n","        # Ccbcr color wheel\n","        img = flow_to_image(flow)\n","        plt.imshow(img)\n","        plt.show()\n","        plt.imsave(\"/FlyingChairs/Train/\"+str(i)+\".png\",img)      # Location to save the visualized UFCFlow model predictions\n","    \n","    return None\n","\n","def visualize_flow_test(flow,i, mode='Y'):\n","    if mode == 'Y':\n","        # Ccbcr color wheel\n","        img = flow_to_image(flow)\n","        plt.imshow(img)\n","        plt.show()\n","        plt.imsave(\"/FlyingChairs/Test/\"+str(i)+\".png\",img)\n","\n","    return None\n","\n","\n","def readFlow(name):\n","    if name.endswith('.pfm') or name.endswith('.PFM'):\n","        return readPFM(name)[0][:,:,0:2]\n","\n","    f = open(name, 'rb')\n","\n","    header = f.read(4)\n","    if header.decode(\"utf-8\") != 'PIEH':\n","        raise Exception('Flow file header does not contain PIEH')\n","\n","    width = np.fromfile(f, np.int32, 1).squeeze()\n","    height = np.fromfile(f, np.int32, 1).squeeze()\n","\n","    flow = np.fromfile(f, np.float32, width * height * 2).reshape((height, width, 2))\n","\n","    return flow.astype(np.float32)\n","\n","\n","def flow_error(tu, tv, u, v):\n","    \"\"\"\n","    Calculate average end point error\n","    :param tu: ground-truth horizontal flow map\n","    :param tv: ground-truth vertical flow map\n","    :param u:  estimated horizontal flow map\n","    :param v:  estimated vertical flow map\n","    :return: End point error of the estimated flow\n","    \"\"\"\n","    smallflow = 0.0\n","    '''\n","    stu = tu[bord+1:end-bord,bord+1:end-bord]\n","    stv = tv[bord+1:end-bord,bord+1:end-bord]\n","    su = u[bord+1:end-bord,bord+1:end-bord]\n","    sv = v[bord+1:end-bord,bord+1:end-bord]\n","    '''\n","    stu = tu[:]\n","    stv = tv[:]\n","    su = u[:]\n","    sv = v[:]\n","\n","    idxUnknow = (abs(stu) > UNKNOWN_FLOW_THRESH) | (abs(stv) > UNKNOWN_FLOW_THRESH)\n","    stu[idxUnknow] = 0\n","    stv[idxUnknow] = 0\n","    su[idxUnknow] = 0\n","    sv[idxUnknow] = 0\n","\n","    ind2 = [(np.absolute(stu) > smallflow) | (np.absolute(stv) > smallflow)]\n","    index_su = su[ind2]\n","    index_sv = sv[ind2]\n","    an = 1.0 / np.sqrt(index_su ** 2 + index_sv ** 2 + 1)\n","    un = index_su * an\n","    vn = index_sv * an\n","\n","    index_stu = stu[ind2]\n","    index_stv = stv[ind2]\n","    tn = 1.0 / np.sqrt(index_stu ** 2 + index_stv ** 2 + 1)\n","    tun = index_stu * tn\n","    tvn = index_stv * tn\n","\n","    epe = np.sqrt((stu - su) ** 2 + (stv - sv) ** 2)\n","    epe = epe[ind2]\n","    mepe = np.mean(epe)\n","    return mepe\n","\n","\n","def flow_to_image(flow):\n","    \"\"\"\n","    Convert flow into middlebury color code image\n","    :param flow: optical flow map\n","    :return: optical flow image in middlebury color\n","    \"\"\"\n","    u = flow[:, :, 0]\n","    v = flow[:, :, 1]\n","\n","    maxu = -999.\n","    maxv = -999.\n","    minu = 999.\n","    minv = 999.\n","\n","    idxUnknow = (abs(u) > UNKNOWN_FLOW_THRESH) | (abs(v) > UNKNOWN_FLOW_THRESH)\n","    u[idxUnknow] = 0\n","    v[idxUnknow] = 0\n","\n","    maxu = max(maxu, np.max(u))\n","    minu = min(minu, np.min(u))\n","\n","    maxv = max(maxv, np.max(v))\n","    minv = min(minv, np.min(v))\n","\n","    rad = np.sqrt(u ** 2 + v ** 2)\n","    maxrad = max(-1, np.max(rad))\n","\n","    print (\"max flow: %.4f\\nflow range:\\nu = %.3f .. %.3f\\nv = %.3f .. %.3f\" % (maxrad, minu,maxu, minv, maxv))\n","\n","    u = u/(maxrad + np.finfo(float).eps)\n","    v = v/(maxrad + np.finfo(float).eps)\n","\n","    img = compute_color(u, v)\n","\n","    idx = np.repeat(idxUnknow[:, :, np.newaxis], 3, axis=2)\n","    img[idx] = 0\n","\n","    return np.uint8(img)\n","\n","\n","def evaluate_flow(gt_flow, pred_flow):\n","    \"\"\"\n","    gt: ground-truth flow\n","    pred: estimated flow\n","    \"\"\"\n","    average_pe = flow_error(gt_flow[:, :, 0], gt_flow[:, :, 1], pred_flow[:, :, 0], pred_flow[:, :, 1])\n","    return average_pe\n","\n","\n","def compute_color(u, v):\n","    \"\"\"\n","    compute optical flow color map\n","    :param u: optical flow horizontal map\n","    :param v: optical flow vertical map\n","    :return: optical flow in color code\n","    \"\"\"\n","    [h, w] = u.shape\n","    img = np.zeros([h, w, 3])\n","    nanIdx = np.isnan(u) | np.isnan(v)\n","    u[nanIdx] = 0\n","    v[nanIdx] = 0\n","\n","    colorwheel = make_color_wheel()\n","    ncols = np.size(colorwheel, 0)\n","\n","    rad = np.sqrt(u**2+v**2)\n","\n","    a = np.arctan2(-v, -u) / np.pi\n","\n","    fk = (a+1) / 2 * (ncols - 1) + 1\n","\n","    k0 = np.floor(fk).astype(int)\n","\n","    k1 = k0 + 1\n","    k1[k1 == ncols+1] = 1\n","    f = fk - k0\n","\n","    for i in range(0, np.size(colorwheel,1)):\n","        tmp = colorwheel[:, i]\n","        col0 = tmp[k0-1] / 255\n","        col1 = tmp[k1-1] / 255\n","        col = (1-f) * col0 + f * col1\n","\n","        idx = rad <= 1\n","        col[idx] = 1-rad[idx]*(1-col[idx])\n","        notidx = np.logical_not(idx)\n","\n","        col[notidx] *= 0.75\n","        img[:, :, i] = np.uint8(np.floor(255 * col*(1-nanIdx)))\n","\n","    return img\n","\n","\n","def make_color_wheel():\n","    \"\"\"\n","    Generate color wheel according Middlebury color code\n","    :return: Color wheel\n","    \"\"\"\n","    RY = 15\n","    YG = 6\n","    GC = 4\n","    CB = 11\n","    BM = 13\n","    MR = 6\n","\n","    ncols = RY + YG + GC + CB + BM + MR\n","\n","    colorwheel = np.zeros([ncols, 3])\n","\n","    col = 0\n","\n","    # RY\n","    colorwheel[0:RY, 0] = 255\n","    colorwheel[0:RY, 1] = np.transpose(np.floor(255*np.arange(0, RY) / RY))\n","    col += RY\n","\n","    # YG\n","    colorwheel[col:col+YG, 0] = 255 - np.transpose(np.floor(255*np.arange(0, YG) / YG))\n","    colorwheel[col:col+YG, 1] = 255\n","    col += YG\n","\n","    # GC\n","    colorwheel[col:col+GC, 1] = 255\n","    colorwheel[col:col+GC, 2] = np.transpose(np.floor(255*np.arange(0, GC) / GC))\n","    col += GC\n","\n","    # CB\n","    colorwheel[col:col+CB, 1] = 255 - np.transpose(np.floor(255*np.arange(0, CB) / CB))\n","    colorwheel[col:col+CB, 2] = 255\n","    col += CB\n","\n","    # BM\n","    colorwheel[col:col+BM, 2] = 255\n","    colorwheel[col:col+BM, 0] = np.transpose(np.floor(255*np.arange(0, BM) / BM))\n","    col += + BM\n","\n","    # MR\n","    colorwheel[col:col+MR, 2] = 255 - np.transpose(np.floor(255 * np.arange(0, MR) / MR))\n","    colorwheel[col:col+MR, 0] = 255\n","\n","    return colorwheel"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KhaGFYCvydfM"},"source":["train_set = pd.read_csv('FC-test.csv') # Loading CSV for train and test image pairs\n","train_img_1_list = train_set['img1'].tolist() \n","train_img_2_list = train_set['img2'].tolist()\n","train_flow_list = train_set['flow'].tolist()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5QmWRZHwydfM"},"source":["# UFCFlow Inference Function for Flying Chairs\n","def inference():\n","    imgpath = \"\"\n","    avgepe= 0.0\n","    for i in range(len(train_set)):\n","        images_dir1 = imgpath+train_img_1_list[i]\n","        img1 =  readImage(images_dir1)\n","        img1=tf.cast(img1,tf.float32)\n","        img1=tf.reshape(img1,(1,384,512,3))\n","        images_dir2 = imgpath+train_img_2_list[i]\n","        img2 =  readImage(images_dir2)\n","        img2=tf.reshape(img2,(1,384,512,3))\n","        img2=tf.cast(img2,tf.float32)\n","        \n","        start=time.time()\n","        flow_out=model(img1,img2)\n","        print ('Time taken for 1 prediction {} sec\\n'.format(time.time() - start))\n","        \n","        test = flow_out['flow'][0].numpy()\n","        test_visualize = visualize_flow_test(flow_out['flow'][0].numpy(),i,mode = 'Y')\n","        gt_flow = readFlow(\"/flow/\"+train_flow_list[i])\n","        \n","        evaluate = evaluate_flow(gt_flow,test)\n","        print(\"Entry\",[i],\":\",evaluate)\n","        avgepe+= evaluate\n","    avg_epe= avgepe/len(train_set)\n","    print(\"Test AEPE:\", avg_epe)\n","        "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pW5jo8OWydfN"},"source":["inference()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qYdXpPtdydfP"},"source":["df= pd.read_csv('') # Loading CSV for MPI Sintel Dataset\n","img1_list = df['img1'].to_list()\n","img2_list = df['img2'].to_list()\n","flow_list = df['flow'].to_list()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zltLru2wydfP"},"source":["# UFCFlow Inference Function for MPI Sintel\n","def inference():\n","\n","    imgpath = \"\"\n","    avgepe= 0.0\n","    for i in range(len(df)):\n","        img1 = tf.io.read_file(imgpath+img1_list[i])\n","        img1 = tf.image.decode_png(img1, channels=3)\n","        img1=tf.cast(img1,tf.float32)\n","        img1=tf.reshape(img1,(1,436,1024,3))\n","\n","        img2 = tf.io.read_file(imgpath+img2_list[i])\n","        img2 = tf.image.decode_png(img2, channels=3)\n","        img2=tf.reshape(img2,(1,436,1024,3))\n","        img2=tf.cast(img2,tf.float32)\n","    \n","        flow_out=model(img1,img2)\n","        \n","        test = flow_out['flow'][0].numpy()\n","        test_visualize = visualize_flow_test(flow_out['flow'][0].numpy(),i,mode = 'Y')\n","        gt_flow = readFlow(\"/flow/\"+flow_list[i])\n","        dim = (512,384)\n","        gt_flow = cv2.resize(gt_flow,dim,interpolation = cv2.INTER_LINEAR )\n","        evaluate = evaluate_flow(gt_flow,test)\n","        print(\"Entry\",[i],\":\",evaluate)\n","        avgepe+= evaluate\n","    avg_epe= avgepe/len(df)\n","    print(\"Test AEPE:\", avg_epe)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J8vkT-DVydfP"},"source":["inference()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sPqYkZ4P3yko"},"source":["Refrences:\r\n","1. Structural Similarity Index Loss Function - Taken from Repository of **nianticlabs** (https://github.com/nianticlabs/monodepth2/blob/master/layers.py)\r\n","\r\n","2. First-Order Smoothness Loss Function, Second-Order Smoothness Loss Function, and Image warping Function - Taken from Repository of **Simon Meister** \r\n","(https://github.com/simonmeister/UnFlow/blob/master/src/e2eflow/core/losses.py)\r\n","(https://github.com/simonmeister/UnFlow/blob/master/src/e2eflow/core/image_warp.py)\r\n","\r\n","3. Visualization Functions - Taken from Repository of **Sam Pepose**\r\n","(https://github.com/sampepose/flownet2-tf/blob/master/src/flowlib.py) \r\n"]}]}